{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyencong1227/Neural-networks-and-deep-learning/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nN1Qv5EZSo_",
        "outputId": "027f34b1-7a47-4bea-eba7-a19ebfd737a5"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-28 10:13:05--  https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84188 (82K) [application/x-httpd-php]\n",
            "Saving to: ‘sentiment labelled sentences.zip’\n",
            "\n",
            "sentiment labelled  100%[===================>]  82.21K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-04-28 10:13:05 (1.41 MB/s) - ‘sentiment labelled sentences.zip’ saved [84188/84188]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqLDPXH6ZePB",
        "outputId": "b8a8a7bb-ce26-43a4-9865-99bf924873f4"
      },
      "source": [
        "!unzip sentences.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sentences.zip\n",
            "   creating: sentiment labelled sentences/\n",
            "  inflating: sentiment labelled sentences/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/sentiment labelled sentences/\n",
            "  inflating: __MACOSX/sentiment labelled sentences/._.DS_Store  \n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/readme.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._readme.txt  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n",
            "  inflating: __MACOSX/._sentiment labelled sentences  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLbDTzsQZnNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36f621b-d1a4-4d78-8d58-8db3af12381c"
      },
      "source": [
        "X = [] # input text\n",
        "y = [] # label\n",
        "\n",
        "f = open(file='a/amazon_cells_labelled.txt', mode='r')\n",
        "for line in f.readlines():\n",
        "  line = line.strip()\n",
        "  line = line.split(\"\\t\")\n",
        "  y.append(int(line[-1]))\n",
        "  X.append(line[0].strip())\n",
        "f.close()\n",
        "\n",
        "f = open('a/yelp_labelled.txt', 'r')\n",
        "for line in f.readlines():\n",
        "  line = line.strip()\n",
        "  line = line.split(\"\\t\")\n",
        "  y.append(int(line[-1]))\n",
        "  X.append(line[0].strip())\n",
        "f.close()\n",
        "\n",
        "f = open('a/imdb_labelled.txt', 'r')\n",
        "for line in f.readlines():\n",
        "  line = line.strip()\n",
        "  line = line.split(\"\\t\")\n",
        "  y.append(int(line[-1]))\n",
        "  X.append(line[0].strip())\n",
        "f.close()\n",
        "\n",
        "\n",
        "print(X[0])\n",
        "print(len(X))\n",
        "print(y[0])\n",
        "print(len(y))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "So there is no way for me to plug it in here in the US unless I go by a converter.\n",
            "3000\n",
            "0\n",
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "qbH_GT3waBCW",
        "outputId": "5020c8d1-3688-4269-f9fd-efa7c9e37b3a"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print(X[0])\n",
        "print(len(X), len(y))\n",
        "plt.hist(y, bins=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "So there is no way for me to plug it in here in the US unless I go by a converter.\n",
            "3000 3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1500.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
              "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
              "           0., 1500.]),\n",
              " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "8RlFdoYSuvWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qywtvjWeyar"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X_seq_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_seq_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_seq_train[0])\n",
        "print(tokenizer.sequences_to_texts([[432, 47]]))\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoEcTcbLvPR3",
        "outputId": "37abd8d2-65e5-493a-8e3a-a3eb98a6954f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[543, 49, 23, 4, 158, 314, 41, 27, 21, 88, 76, 21, 559, 12]\n",
            "['meal really']\n",
            "Obviously they have a terrible customer service, so you get what you pay for.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WahVTGjpfbVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f1f26c-8f7b-40a5-ea3b-bccc12344313"
      },
      "source": [
        "for i in X_seq_train[0]:\n",
        "   print(f\"{i} -----> {tokenizer.index_word[i]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "543 -----> obviously\n",
            "49 -----> they\n",
            "23 -----> have\n",
            "4 -----> a\n",
            "158 -----> terrible\n",
            "314 -----> customer\n",
            "41 -----> service\n",
            "27 -----> so\n",
            "21 -----> you\n",
            "88 -----> get\n",
            "76 -----> what\n",
            "21 -----> you\n",
            "559 -----> pay\n",
            "12 -----> for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_wXrdU-fl7d",
        "outputId": "b7c1254d-604f-4ef0-9199-fed69475a258"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = max([len(t) for t in X_seq_train] + [len(t) for t in X_seq_test])\n",
        "print(max_length)\n",
        "X_pad_train = pad_sequences(sequences=X_seq_train, \n",
        "                              maxlen=max_length, \n",
        "                              padding='post')\n",
        "\n",
        "print(X_pad_train.shape)\n",
        "\n",
        "X_pad_test = pad_sequences(sequences=X_seq_test, \n",
        "                              maxlen=max_length,     \n",
        "                              padding='post')\n",
        "print(X_pad_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "(2400, 59)\n",
            "(600, 59)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJH9JLHldLf",
        "outputId": "45c5c0c4-3001-4c70-ea11-e08ff24b1740"
      },
      "source": [
        "X_pad_train[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  67,    1,   28,  169,  692,    7, 1681,  315, 1682, 1233,   60,\n",
              "        662,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPGe5IhDmWEX",
        "outputId": "33b6a3d6-de97-4c9f-dbdc-7181fd039a50"
      },
      "source": [
        "# ML: X_pad ->  sentiment \n",
        "from tensorflow.keras.layers import Embedding, Input, Conv1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "vocab_size = 2000\n",
        "p = 0.1\n",
        "\n",
        "inp = Input(shape=(max_length))\n",
        "x = Embedding(vocab_size, 128, input_length=max_length)(inp)\n",
        "x = Dropout(p)(x)\n",
        "x = Conv1D(filters=32, kernel_size=3, \n",
        "           padding='same', activation='relu')(x)\n",
        "\n",
        "x = Dropout(p)(x)\n",
        "x = Conv1D(filters=16, kernel_size=3, \n",
        "           padding='same', activation='relu')(x)\n",
        "\n",
        "# collect features: poolling??? -> inovations \n",
        "# dãn ma trận 59 x 16 -> 944-vector\n",
        "#x = Flatten()(x)\n",
        "\n",
        "# Trung bình hoá các feature của chuỗi\n",
        "x = K.mean(x, keepdims=False, axis=1)\n",
        "\n",
        "# Fully connected layer for classification\n",
        "x = Dense(units=16, activation='relu')(x)\n",
        "x = Dropout(p)(x)\n",
        "x = Dense(units=1, activation='sigmoid')(x) # xác suất để x là positive \n",
        "\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.summary()\n",
        "\n",
        "# compile model -> optimizer, loss, evaluation metrics\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 59)]              0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 59, 128)           256000    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 59, 128)           0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 59, 32)            12320     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 59, 32)            0         \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 59, 16)            1552      \n",
            "                                                                 \n",
            " tf.math.reduce_mean_4 (TFOp  (None, 16)               0         \n",
            " Lambda)                                                         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 270,161\n",
            "Trainable params: 270,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKVKmF92uiay",
        "outputId": "72e4c0b7-a7e0-44f4-f25c-6aea1aa31048"
      },
      "source": [
        "y = np.array(y)\n",
        "model.fit(X_pad_train, np.array(y_train), \n",
        "          epochs=10, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0870 - acc: 0.9766 - val_loss: 0.6806 - val_acc: 0.7812\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0766 - acc: 0.9797 - val_loss: 0.7349 - val_acc: 0.7958\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0640 - acc: 0.9844 - val_loss: 0.7940 - val_acc: 0.7937\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.0503 - acc: 0.9870 - val_loss: 0.8479 - val_acc: 0.7771\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0487 - acc: 0.9875 - val_loss: 0.9169 - val_acc: 0.7729\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0394 - acc: 0.9911 - val_loss: 0.9831 - val_acc: 0.7833\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0413 - acc: 0.9880 - val_loss: 1.0154 - val_acc: 0.7667\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0338 - acc: 0.9932 - val_loss: 1.0947 - val_acc: 0.7750\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.0306 - acc: 0.9932 - val_loss: 1.1242 - val_acc: 0.7667\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.0303 - acc: 0.9948 - val_loss: 1.1659 - val_acc: 0.7771\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4517ee450>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_pad_test)\n",
        "y_pred[y_pred>0.5] = 1\n",
        "y_pred[y_pred<=0.5] = 0\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJaIiMGD1XT9",
        "outputId": "a5411fea-f93b-47bf-c0ef-711f3c4b2dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81       317\n",
            "           1       0.77      0.86      0.81       283\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.82      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLWFVQ7hvCjQ",
        "outputId": "8a1165b5-e189-447f-d25a-e2a000e95d41"
      },
      "source": [
        "def predict(seq, model):\n",
        "  test_text = [seq]\n",
        "  X_test = tokenizer.texts_to_sequences(test_text)\n",
        "  X_test_padd = pad_sequences(sequences=X_test, maxlen=max_length, padding='post')\n",
        "\n",
        "  p = model.predict(X_test_padd)[0, 0]\n",
        "\n",
        "  if p > 0.5: \n",
        "    return \"Positive\", p\n",
        "  else:\n",
        "    return \"Negatvie\", p\n",
        "\n",
        "seq = \"it is terrible today\"\n",
        "\n",
        "predict(seq, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Negatvie', 0.011948526)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdBVhToUvLhD",
        "outputId": "c128cf63-8696-4191-f688-38af92cfa100"
      },
      "source": [
        "y[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JkJyTKMv3Yj",
        "outputId": "0abc6d8f-548a-42a1-edaf-c87c40e0a819"
      },
      "source": [
        "seq = np.array([[0, 1, 0], \n",
        "                [1, 0,  0], \n",
        "                [0, 0, 1]])\n",
        "\n",
        "Wh = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) # 1 layer -> #row = #input, #col = #output\n",
        "Wx = np.array([[0.1, 0.2, 0.3], [.4, .5, .6], [.7, .8, .9]])\n",
        "\n",
        "ho = np.array([0, 0, 0])\n",
        "\n",
        "g = lambda z: np.tanh(z)\n",
        "for i in range(3):\n",
        "  h1 = g(np.dot([ho], Wh) + np.dot(seq[i], Wx))\n",
        "  print(h1)\n",
        "\n",
        "  ho = h1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.37994896 0.46211716 0.53704957]]\n",
            "[[[0.99998969 0.99999946 0.99999997]]]\n",
            "[[[[1. 1. 1.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7XTDZkS4pUt",
        "outputId": "97cd597e-cb0f-4865-df84-f6c853760452"
      },
      "source": [
        "# text -> RNN -> using final state as the features of text\n",
        "# seq = \"the phone was broken on shipping, terrible\" -> RNN -> final state ->FC layer -> sentiment\n",
        "\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "inp = Input(shape=(max_length))\n",
        "x = Embedding(vocab_size, 128, input_length=200)(inp)\n",
        "x, h, c = LSTM(units=128, return_state=True)(x)\n",
        "\n",
        "y = Dense(units=64, activation='relu')(h)\n",
        "y = Dense(units=1, activation='sigmoid')(y)\n",
        "\n",
        "model = Model(inputs=inp, outputs=y)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# compile model -> optimizer, loss, evaluation metrics\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 32, 128)           256000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 128), (None, 128) 131584    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 395,905\n",
            "Trainable params: 395,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmYP6j2x9KBX",
        "outputId": "d13e4a69-478a-4b1c-8954-addf9fb66004"
      },
      "source": [
        "y = np.array(y)\n",
        "model.fit(X_padd[500:], y[500:], \n",
        "          epochs=10, batch_size=64, \n",
        "          validation_data=(X_padd[:500], y[:500]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 2s 76ms/step - loss: 0.0542 - acc: 0.9873 - val_loss: 0.5248 - val_acc: 0.8500\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 2s 76ms/step - loss: 0.0438 - acc: 0.9887 - val_loss: 0.5974 - val_acc: 0.8500\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 2s 76ms/step - loss: 0.0334 - acc: 0.9920 - val_loss: 0.7068 - val_acc: 0.8460\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 2s 74ms/step - loss: 0.0224 - acc: 0.9967 - val_loss: 0.5874 - val_acc: 0.8500\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 2s 75ms/step - loss: 0.0318 - acc: 0.9940 - val_loss: 0.8726 - val_acc: 0.8340\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 2s 75ms/step - loss: 0.0344 - acc: 0.9927 - val_loss: 0.6230 - val_acc: 0.8260\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 2s 74ms/step - loss: 0.0338 - acc: 0.9920 - val_loss: 0.6624 - val_acc: 0.8420\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 2s 76ms/step - loss: 0.0184 - acc: 0.9967 - val_loss: 0.9489 - val_acc: 0.8260\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 2s 76ms/step - loss: 0.0259 - acc: 0.9947 - val_loss: 0.9105 - val_acc: 0.8400\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 2s 76ms/step - loss: 0.0389 - acc: 0.9913 - val_loss: 0.7173 - val_acc: 0.8460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f083a2ac110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhlcCNaL9x_d",
        "outputId": "c12722fb-58c3-4f21-bfa3-aedea3fb9a15"
      },
      "source": [
        "def predict(seq, model):\n",
        "  test_text = [seq]\n",
        "  X_test = tokenizer.texts_to_sequences(test_text)\n",
        "  X_test_padd = pad_sequences(sequences=X_test, maxlen=max_length, padding='post')\n",
        "\n",
        "  p = model.predict(X_test_padd)[0, 0]\n",
        "\n",
        "  if p > 0.5: \n",
        "    return \"Positive\", p\n",
        "  else:\n",
        "    return \"Negatvie\", p\n",
        "\n",
        "seq = \"the phone was broken on shipping\"\n",
        "\n",
        "predict(seq, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Negatvie', 0.010690421)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nblMN0Ep-EUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93265b3c-083b-4f9f-af72-0f1f3e6610ea"
      },
      "source": [
        "help(open)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on built-in function open in module io:\n",
            "\n",
            "open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)\n",
            "    Open file and return a stream.  Raise OSError upon failure.\n",
            "    \n",
            "    file is either a text or byte string giving the name (and the path\n",
            "    if the file isn't in the current working directory) of the file to\n",
            "    be opened or an integer file descriptor of the file to be\n",
            "    wrapped. (If a file descriptor is given, it is closed when the\n",
            "    returned I/O object is closed, unless closefd is set to False.)\n",
            "    \n",
            "    mode is an optional string that specifies the mode in which the file\n",
            "    is opened. It defaults to 'r' which means open for reading in text\n",
            "    mode.  Other common values are 'w' for writing (truncating the file if\n",
            "    it already exists), 'x' for creating and writing to a new file, and\n",
            "    'a' for appending (which on some Unix systems, means that all writes\n",
            "    append to the end of the file regardless of the current seek position).\n",
            "    In text mode, if encoding is not specified the encoding used is platform\n",
            "    dependent: locale.getpreferredencoding(False) is called to get the\n",
            "    current locale encoding. (For reading and writing raw bytes use binary\n",
            "    mode and leave encoding unspecified.) The available modes are:\n",
            "    \n",
            "    ========= ===============================================================\n",
            "    Character Meaning\n",
            "    --------- ---------------------------------------------------------------\n",
            "    'r'       open for reading (default)\n",
            "    'w'       open for writing, truncating the file first\n",
            "    'x'       create a new file and open it for writing\n",
            "    'a'       open for writing, appending to the end of the file if it exists\n",
            "    'b'       binary mode\n",
            "    't'       text mode (default)\n",
            "    '+'       open a disk file for updating (reading and writing)\n",
            "    'U'       universal newline mode (deprecated)\n",
            "    ========= ===============================================================\n",
            "    \n",
            "    The default mode is 'rt' (open for reading text). For binary random\n",
            "    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
            "    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
            "    raises an `FileExistsError` if the file already exists.\n",
            "    \n",
            "    Python distinguishes between files opened in binary and text modes,\n",
            "    even when the underlying operating system doesn't. Files opened in\n",
            "    binary mode (appending 'b' to the mode argument) return contents as\n",
            "    bytes objects without any decoding. In text mode (the default, or when\n",
            "    't' is appended to the mode argument), the contents of the file are\n",
            "    returned as strings, the bytes having been first decoded using a\n",
            "    platform-dependent encoding or using the specified encoding if given.\n",
            "    \n",
            "    'U' mode is deprecated and will raise an exception in future versions\n",
            "    of Python.  It has no effect in Python 3.  Use newline to control\n",
            "    universal newlines mode.\n",
            "    \n",
            "    buffering is an optional integer used to set the buffering policy.\n",
            "    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
            "    line buffering (only usable in text mode), and an integer > 1 to indicate\n",
            "    the size of a fixed-size chunk buffer.  When no buffering argument is\n",
            "    given, the default buffering policy works as follows:\n",
            "    \n",
            "    * Binary files are buffered in fixed-size chunks; the size of the buffer\n",
            "      is chosen using a heuristic trying to determine the underlying device's\n",
            "      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
            "      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
            "    \n",
            "    * \"Interactive\" text files (files for which isatty() returns True)\n",
            "      use line buffering.  Other text files use the policy described above\n",
            "      for binary files.\n",
            "    \n",
            "    encoding is the name of the encoding used to decode or encode the\n",
            "    file. This should only be used in text mode. The default encoding is\n",
            "    platform dependent, but any encoding supported by Python can be\n",
            "    passed.  See the codecs module for the list of supported encodings.\n",
            "    \n",
            "    errors is an optional string that specifies how encoding errors are to\n",
            "    be handled---this argument should not be used in binary mode. Pass\n",
            "    'strict' to raise a ValueError exception if there is an encoding error\n",
            "    (the default of None has the same effect), or pass 'ignore' to ignore\n",
            "    errors. (Note that ignoring encoding errors can lead to data loss.)\n",
            "    See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
            "    for a list of the permitted encoding error strings.\n",
            "    \n",
            "    newline controls how universal newlines works (it only applies to text\n",
            "    mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
            "    follows:\n",
            "    \n",
            "    * On input, if newline is None, universal newlines mode is\n",
            "      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
            "      these are translated into '\\n' before being returned to the\n",
            "      caller. If it is '', universal newline mode is enabled, but line\n",
            "      endings are returned to the caller untranslated. If it has any of\n",
            "      the other legal values, input lines are only terminated by the given\n",
            "      string, and the line ending is returned to the caller untranslated.\n",
            "    \n",
            "    * On output, if newline is None, any '\\n' characters written are\n",
            "      translated to the system default line separator, os.linesep. If\n",
            "      newline is '' or '\\n', no translation takes place. If newline is any\n",
            "      of the other legal values, any '\\n' characters written are translated\n",
            "      to the given string.\n",
            "    \n",
            "    If closefd is False, the underlying file descriptor will be kept open\n",
            "    when the file is closed. This does not work when a file name is given\n",
            "    and must be True in that case.\n",
            "    \n",
            "    A custom opener can be used by passing a callable as *opener*. The\n",
            "    underlying file descriptor for the file object is then obtained by\n",
            "    calling *opener* with (*file*, *flags*). *opener* must return an open\n",
            "    file descriptor (passing os.open as *opener* results in functionality\n",
            "    similar to passing None).\n",
            "    \n",
            "    open() returns a file object whose type depends on the mode, and\n",
            "    through which the standard file operations such as reading and writing\n",
            "    are performed. When open() is used to open a file in a text mode ('w',\n",
            "    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
            "    a file in a binary mode, the returned class varies: in read binary\n",
            "    mode, it returns a BufferedReader; in write binary and append binary\n",
            "    modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
            "    a BufferedRandom.\n",
            "    \n",
            "    It is also possible to use a string or bytearray as a file for both\n",
            "    reading and writing. For strings StringIO can be used like a file\n",
            "    opened in a text mode, and for bytes a BytesIO can be used like a file\n",
            "    opened in a binary mode.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8ieXurkxsReC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}